{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "260832907-Assignment-6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FuO82RTBftK"
      },
      "source": [
        "# 1. Language Modeling\n",
        "\n",
        "In this part, let's generate text using a trigram language model.\n",
        "\n",
        "Go to https://drive.google.com/drive/folders/1pR0koayRSgXfTD72HZUHN14uec0SrnXy?usp=sharing and click add shortcut to drive. This will add the data required for this problem set to your Google drive.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1LqHisiziX8Ri94Xs6Cv8mhx6vivFM3kS\" alt=\"Drawing\" height=\"300\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtZEcHthBeXz"
      },
      "source": [
        "Run the below code snippet. It will generate a URL which generates an authorization code.* Enter it below to give Colab access to your Google drive. \n",
        "\n",
        "*Copy function may not work. If so, manually copy the authorization code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KW-dce7oJlyr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5998572-ad25-405a-9771-13e049656fe4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni2pYuuQKaHY"
      },
      "source": [
        "When you run the `ls` command below, you should see these folders.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYENtyc7SOxA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc44c925-f093-48e6-d468-595d88138e71"
      },
      "source": [
        "!ls \"/content/drive/My Drive/nl2ds\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "semantic-parser  tweets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import packages."
      ],
      "metadata": {
        "id": "BOTnmFJOMlAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import string\n",
        "import nltk\n",
        "import gensim\n",
        "import numpy as np\n",
        "from math import log\n",
        "from collections import Counter\n",
        "from nltk.data import find\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "nltk.download('word2vec_sample')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIfpgITVMhus",
        "outputId": "978e19fa-52e8-4fa8-df6d-50c91c77b2b3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package word2vec_sample to /root/nltk_data...\n",
            "[nltk_data]   Package word2vec_sample is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2Y7I_9lPoZS"
      },
      "source": [
        "Let's load the trigrams first. You can change the below code as you see fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZMOmElPSPHk"
      },
      "source": [
        "bigram_prefix_to_trigram = {}\n",
        "bigram_prefix_to_trigram_weights = {}\n",
        "\n",
        "lines = open(\"/content/drive/My Drive/nl2ds/tweets/covid-tweets-2020-08-10-2020-08-21.trigrams.txt\").readlines()\n",
        "# lines = open(\"nl2ds/tweets/covid-tweets-2020-08-10-2020-08-21.trigrams.txt\").readlines()\n",
        "for line in lines:\n",
        "    word1, word2, word3, count = line.strip().split()\n",
        "    if (word1, word2) not in bigram_prefix_to_trigram:\n",
        "        bigram_prefix_to_trigram[(word1, word2)] = []\n",
        "        bigram_prefix_to_trigram_weights[(word1, word2)] = []\n",
        "    bigram_prefix_to_trigram[(word1, word2)].append(word3)\n",
        "    bigram_prefix_to_trigram_weights[(word1, word2)].append(int(count))\n",
        "\n",
        "# freeup memory\n",
        "lines = None"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X48i3rarPzd8"
      },
      "source": [
        "## Problem 1.1: Retrieve top next words and their probability given a bigram prefix.\n",
        "\n",
        "For the following prefixes **word1=middle, word2=of, and n=10**, the output is:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "a 0.807981220657277\n",
        "the 0.06948356807511737\n",
        "pandemic 0.023943661971830985\n",
        "this 0.016901408450704224\n",
        "an 0.0107981220657277\n",
        "...\n",
        "...\n",
        "...\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYhal88xSYow",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35a70e64-f69e-421f-aa0c-13d50ba21b40"
      },
      "source": [
        "def top_next_word(word1, word2, n=10):\n",
        "    # write your code here\n",
        "    all_word3 = bigram_prefix_to_trigram[(word1, word2)]\n",
        "    all_word3_weights = bigram_prefix_to_trigram_weights[(word1, word2)]\n",
        "    \n",
        "    sum_weights = sum(all_word3_weights)\n",
        "    \n",
        "    next_words = []\n",
        "    probs = []\n",
        "    \n",
        "    for i in range(n):\n",
        "        if i < len(all_word3):\n",
        "            next_words.append(all_word3[i])\n",
        "            probs.append(all_word3_weights[i]/sum_weights)\n",
        "        \n",
        "    return next_words, probs\n",
        "\n",
        "next_words, probs = top_next_word(\"middle\", \"of\", 10)\n",
        "for word, prob in zip(next_words, probs):\n",
        "    print(word, prob)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a 0.807981220657277\n",
            "the 0.06948356807511737\n",
            "pandemic 0.023943661971830985\n",
            "this 0.016901408450704224\n",
            "an 0.0107981220657277\n",
            "covid 0.009389671361502348\n",
            "nowhere 0.008450704225352112\n",
            "it 0.004694835680751174\n",
            "lockdown 0.002347417840375587\n",
            "summer 0.002347417840375587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gok10i2dSHXB"
      },
      "source": [
        "## Problem 1.2: Sampling n words\n",
        "\n",
        "Sample next n words given a bigram prefix. Use the probablity distribution defined by the frequency counts. Functions like **numpy.random.choice** will be useful here. Sample without repitition, otherwise all your samples will contain the most frequent trigram.\n",
        "\n",
        "\n",
        "For the following prefixes **word1=middle, word2=of, and n=10**, the output could be as follows (our outputs may differ): \n",
        "\n",
        "```\n",
        "a 0.807981220657277\n",
        "pandemic 0.023943661971830985\n",
        "nowhere 0.008450704225352112\n",
        "the 0.06948356807511737\n",
        "...\n",
        "...\n",
        "...\n",
        "...\n",
        "...\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OzYJoYfUaom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7d83582-2e2d-4e85-a43f-50ab90c14a78"
      },
      "source": [
        "def sample_next_word(word1, word2, n=10):\n",
        "    # write your code here\n",
        "    all_word3 = bigram_prefix_to_trigram[(word1, word2)]\n",
        "    all_word3_weights = bigram_prefix_to_trigram_weights[(word1, word2)]\n",
        "    \n",
        "    sum_weights = sum(all_word3_weights)\n",
        "        \n",
        "    next_words = []\n",
        "    probs = []\n",
        "    \n",
        "    if len(all_word3) >= n:\n",
        "        indices = np.random.choice(len(all_word3), n, replace=False)\n",
        "    else:\n",
        "        indices = np.random.choice(len(all_word3), len(all_word3), replace=False)\n",
        "    \n",
        "    for i in indices:\n",
        "        next_words.append(all_word3[i])\n",
        "        probs.append(all_word3_weights[i]/sum_weights)\n",
        "        \n",
        "    return next_words, probs\n",
        "\n",
        "\n",
        "next_words, probs = sample_next_word(\"middle\", \"of\", 10)\n",
        "for word, prob in zip(next_words, probs):\n",
        "    print(word, prob)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "planning 0.00046948356807511736\n",
            "night 0.00046948356807511736\n",
            "may 0.0009389671361502347\n",
            "stage 0.0018779342723004694\n",
            "their 0.00046948356807511736\n",
            "tour 0.00046948356807511736\n",
            "highway 0.00046948356807511736\n",
            "#covid19 0.0018779342723004694\n",
            "armageddon 0.00046948356807511736\n",
            "writing 0.00046948356807511736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyYenU8H-fIR"
      },
      "source": [
        "## Problem 1.3: Generate sentences starting with a prefix\n",
        "\n",
        "Generates n-sentences starting with a given sentence prefix. Use [beam search](https://en.wikipedia.org/wiki/Beam_search) to generate multiple sentences. Depending on which method you use to generate next word, you will get different outputs. When you generate <EOS> in a path, stop exploring that path. If you are not careful with your implementation, you may end up in an infinite loop.\n",
        "\n",
        "If you use the method `word_generator=top_next_word`, `beam=10` and prefix is `<BOS1> <BOS2> trump`, your output is as follows:\n",
        "```\n",
        "<BOS1> <BOS2> trump eyes new unproven coronavirus treatment URL <EOS> 0.00021893147502903603\n",
        "<BOS1> <BOS2> trump eyes new unproven coronavirus cure URL <EOS> 0.0001719607222046247\n",
        "<BOS1> <BOS2> trump eyes new unproven virus cure promoted by mypillow ceo over unproven therapeutic URL <EOS> 9.773272077557522e-05\n",
        "...\n",
        "...\n",
        "...\n",
        "```\n",
        "\n",
        "\n",
        "If you use the method `word_generator=top_next_word`, `beam=10` and prefix is `<BOS1> <BOS2> biden`, your output is as follows:\n",
        "```\n",
        "<BOS1> <BOS2> biden calls for a 30 bonus URL #cashgem #cashappfriday #stayathome <EOS> 0.0002495268686322749\n",
        "<BOS1> <BOS2> biden says all u.s. governors should mandate masks <EOS> 1.6894510541025754e-05\n",
        "<BOS1> <BOS2> biden says all u.s. governors question cost of a pandemic <EOS> 8.777606198953028e-07\n",
        "...\n",
        "...\n",
        "...\n",
        "```\n",
        "\n",
        "\n",
        "If you use the method `word_generator=sample_next_word`, `beam=10` and prefix is `<BOS1> <BOS2> trump`, your output may look as follows (since this is sampling, our outputs will difer):\n",
        "\n",
        "```\n",
        "<BOS1> <BOS2> trump signs executive orders URL <EOS> 7.150992253427233e-05\n",
        "<BOS1> <BOS2> trump signs executive actions URL <EOS> 7.117242889600614e-05\n",
        "<BOS1> <BOS2> trump news president attacked over it <EOS> 1.0546494007903964e-05\n",
        "<BOS1> <BOS2> trump news president attacked over executive orders URL <EOS> 1.0126405114118984e-05\n",
        "```\n",
        "\n",
        "If you use the method `word_generator=sample_next_word`, `beam=10` and prefix is `<BOS1> <BOS2> biden`, your output may look as follows:\n",
        "\n",
        "```\n",
        "<BOS1> <BOS2> biden harris 2020 <EOS> 0.0015758924114719264\n",
        "<BOS1> <BOS2> biden harris 2020 URL <EOS> 0.0006443960952032196\n",
        "<BOS1> <BOS2> biden calls for evictions ban so marylander 's do it URL <EOS> 4.105215709355001e-07\n",
        "<BOS1> <BOS2> biden calls for evictions ban so marylander 's do our best to stay home <EOS> 1.3158806336098573e-09\n",
        "...\n",
        "...\n",
        "...\n",
        "...\n",
        "...\n",
        "```\n",
        "\n",
        "Hope you see that sampling gives different outputs compared to deterministically picking the top n-words.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40kW0joweXFO"
      },
      "source": [
        "# assume n=10 for sampler\n",
        "def generate_sentences(prefix, sampler, beam=10):\n",
        "    # write your code\n",
        "    n = 10\n",
        "\n",
        "    # len(sentences) = beam = 10\n",
        "    # len(all_probs) = beam = 10\n",
        "    sentences = []\n",
        "    all_probs = []\n",
        "    \n",
        "    trigram = prefix.split()\n",
        "    word1 = trigram[0]\n",
        "    word2 = trigram[1]\n",
        "    word3 = trigram[2]\n",
        "    \n",
        "    # add first three words to sentences\n",
        "    for i in range(beam):\n",
        "        sentences.append(f'{word1} {word2} {word3}')\n",
        "        all_probs.append(1)\n",
        "        \n",
        "    if word3 == '<EOS>':\n",
        "        return sentences, all_probs\n",
        "    \n",
        "    else:\n",
        "        # list of n=10 words and list of n=10 probabilities\n",
        "        next_words_23, probs_23 = sampler(word2, word3, n)\n",
        "\n",
        "        # beam*n = 10*10 = 100\n",
        "        sentences_100 = []\n",
        "        all_probs_100 = []\n",
        "\n",
        "        # count for populating 100 list\n",
        "        count = 0\n",
        "        # get word4\n",
        "        for i in range(len(next_words_23)):\n",
        "            word4 = next_words_23[i]\n",
        "            prob4 = probs_23[i]\n",
        "\n",
        "            # add to 10 list\n",
        "            sentences[i] = sentences[i] + ' ' + word4\n",
        "            all_probs[i] = all_probs[i]*prob4\n",
        "            \n",
        "            if word4 != '<EOS>':               \n",
        "                next_words_34, probs_34 = sampler(word3, word4, n)\n",
        "\n",
        "                # get word5\n",
        "                for j in range(len(next_words_34)):\n",
        "                    word5 = next_words_34[j]\n",
        "                    prob5 = probs_34[j]\n",
        "\n",
        "                    # populate 100 list\n",
        "                    sentences_100.append(sentences[i])\n",
        "                    all_probs_100.append(all_probs[i])\n",
        "\n",
        "                    # add to 100 list\n",
        "                    sentences_100[count] = sentences_100[count] + ' ' + word5\n",
        "                    all_probs_100[count] = all_probs_100[count]*prob5\n",
        "\n",
        "                    count += 1\n",
        "\n",
        "        # top 10 sorted\n",
        "        top_10 = [(x,y) for y,x in sorted(zip(all_probs,sentences), key=lambda pair: pair[0], reverse=True)]\n",
        "        top_10 = [(x,y) for (x,y) in top_10 if x[-5:] == '<EOS>']\n",
        "\n",
        "        # top 100 sorted\n",
        "        top_100 = [(x,y) for y,x in sorted(zip(all_probs_100,sentences_100), key=lambda pair: pair[0], reverse=True)]\n",
        "\n",
        "        while (len(top_10) < beam):\n",
        "            for i in range(beam-len(top_10)):\n",
        "                if i < len(top_100):\n",
        "                    top_10.append(top_100[i])\n",
        "\n",
        "            sentences = [x for (x,y) in top_10]\n",
        "            all_probs = [y for (x,y) in top_10]\n",
        "\n",
        "            sentences_100 = []\n",
        "            all_probs_100 = []\n",
        "\n",
        "            count = 0\n",
        "            # if not <EOS>, then find next word\n",
        "            for i in range(len(sentences)):\n",
        "                x = sentences[i]\n",
        "                if x[-5:] != '<EOS>':\n",
        "                    ngram = x.split()\n",
        "                    word1 = ngram[-2]\n",
        "                    word2 = ngram[-1]\n",
        "\n",
        "                    next_words_12, probs_12 = sampler(word1, word2, n)\n",
        "\n",
        "                    # get word3\n",
        "                    for j in range(len(next_words_12)):\n",
        "                        word3 = next_words_12[j]\n",
        "                        prob3 = probs_12[j]\n",
        "\n",
        "                        sentences_100.append(sentences[i])\n",
        "                        all_probs_100.append(all_probs[i])\n",
        "\n",
        "                        sentences_100[count] = sentences_100[count] + ' ' + word3\n",
        "                        all_probs_100[count] = all_probs_100[count]*prob3\n",
        "\n",
        "                        count += 1\n",
        "\n",
        "            # top 10 sorted\n",
        "            top_10 = [(x,y) for y,x in sorted(zip(all_probs,sentences), key=lambda pair: pair[0], reverse=True)]\n",
        "            top_10 = [(x,y) for (x,y) in top_10 if x[-5:] == '<EOS>']\n",
        "\n",
        "            # top 100 sorted\n",
        "            top_100 = [(x,y) for y,x in sorted(zip(all_probs_100,sentences_100), key=lambda pair: pair[0], reverse=True)]\n",
        "\n",
        "        sentences = [x for (x,y) in top_10]\n",
        "        all_probs = [y for (x,y) in top_10]\n",
        "\n",
        "        return sentences, all_probs"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences, probs = generate_sentences(prefix=\"<BOS1> <BOS2> trump\", beam=10, sampler=top_next_word)\n",
        "for sent, prob in zip(sentences, probs):\n",
        "    print(sent, prob)\n",
        "print(\"--------------------------------------------------\")\n",
        "\n",
        "sentences, probs = generate_sentences(prefix=\"<BOS1> <BOS2> biden\", beam=10, sampler=top_next_word)\n",
        "for sent, prob in zip(sentences, probs):\n",
        "    print(sent, prob)\n",
        "print(\"--------------------------------------------------\")\n",
        "\n",
        "sentences, probs = generate_sentences(prefix=\"<BOS1> <BOS2> trump\", beam=10, sampler=sample_next_word)\n",
        "for sent, prob in zip(sentences, probs):\n",
        "    print(sent, prob)\n",
        "print(\"--------------------------------------------------\")\n",
        "\n",
        "sentences, probs = generate_sentences(prefix=\"<BOS1> <BOS2> biden\", beam=10, sampler=sample_next_word)\n",
        "for sent, prob in zip(sentences, probs):\n",
        "    print(sent, prob)\n",
        "print(\"--------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8K77rVe_Mqw",
        "outputId": "6c1b1f89-6da9-42e9-f410-81715b3c8068"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<BOS1> <BOS2> trump eyes new unproven coronavirus treatment URL <EOS> 0.00021893147502903603\n",
            "<BOS1> <BOS2> trump eyes new unproven coronavirus cure URL <EOS> 0.0001719607222046247\n",
            "<BOS1> <BOS2> trump eyes new unproven virus cure promoted by mypillow ceo over unproven therapeutic URL <EOS> 9.773272077557522e-05\n",
            "<BOS1> <BOS2> trump eyes new unproven coronavirus therapeutic mypillow creator over unproven therapeutic URL <EOS> 8.212549111137046e-05\n",
            "<BOS1> <BOS2> trump eyes new unproven virus cure promoted by ben carson and mypillow founder URL <EOS> 1.2095697936835552e-05\n",
            "<BOS1> <BOS2> trump eyes new unproven virus cure promoted by mypillow ceo over unproven therapeutic URL via @USER <EOS> 7.432226908194607e-06\n",
            "<BOS1> <BOS2> trump eyes new unproven virus cure promoted by mypillow ceo over unproven and dangerous <EOS> 5.61685494684627e-06\n",
            "<BOS1> <BOS2> trump eyes new unproven virus cure promoted by mypillow ceo over unproven and dangerous covid-19 treatment URL <EOS> 5.235550241426875e-06\n",
            "<BOS1> <BOS2> trump eyes new unproven virus cure promoted by ben carson and mypillow founder and ceo of mypillow URL <EOS> 2.1484173056680325e-06\n",
            "<BOS1> <BOS2> trump eyes new unproven virus cure promoted by ben carson and mypillow founder and ceo mike lindell a big deal and the pandemic <EOS> 4.890594996717161e-12\n",
            "--------------------------------------------------\n",
            "<BOS1> <BOS2> biden calls for a 30 bonus URL #cashgem #cashappfriday #stayathome <EOS> 0.0002495268686322749\n",
            "<BOS1> <BOS2> biden says all u.s. governors should mandate masks <EOS> 1.6894510541025754e-05\n",
            "<BOS1> <BOS2> biden says all u.s. governors question cost of a pandemic <EOS> 8.777606198953028e-07\n",
            "<BOS1> <BOS2> biden says all u.s. governors should mandate mandatory mask rule URL <EOS> 6.46094976762742e-07\n",
            "<BOS1> <BOS2> biden says all u.s. governors should mandate masks and social distancing <EOS> 4.6833316176693136e-07\n",
            "<BOS1> <BOS2> biden says all u.s. governors should mandate mandatory mask wearing and social distancing <EOS> 4.380454675651422e-08\n",
            "<BOS1> <BOS2> biden says all u.s. governors should mandate mandatory mask wearing and social distancing URL <EOS> 2.2277082512658355e-08\n",
            "<BOS1> <BOS2> biden says all u.s. governors should mandate mandatory mask wearing and social distancing and wearing masks <EOS> 1.166766912614153e-10\n",
            "<BOS1> <BOS2> biden says all u.s. governors should mandate mandatory mask wearing and social distancing and wearing a mask <EOS> 1.1355525098965152e-10\n",
            "<BOS1> <BOS2> biden says all u.s. governors should mandate mandatory mask wearing and social distancing and wearing a mask and social distancing and masks are not the same time <EOS> 2.3660719518591428e-20\n",
            "--------------------------------------------------\n",
            "<BOS1> <BOS2> trump escorted from briefing URL <EOS> 4.550168958479709e-05\n",
            "<BOS1> <BOS2> trump unveils new website #gruene #canyonlake #springbranch #newbraunfels #sanmarcos #gruene #sanmarcos #smithvilletx #austin #2ndamendment URL <EOS> 4.169272461955389e-05\n",
            "<BOS1> <BOS2> trump genocide rages trump cheats his wives had pregnancy tests #trumpisanationaldisgrace #covid19 <EOS> 1.1291779584462513e-06\n",
            "<BOS1> <BOS2> trump genocide rages trump cheats his wives had pregnancy tests #trumpisanationaldisgrace #covid19 #testing #maga #covididiots #coronavirus URL <EOS> 4.154983829780578e-08\n",
            "<BOS1> <BOS2> trump genocide rages trump cheats his wives had pregnancy tests #trumpisanationaldisgrace #covid19 #testing #maga #covididiots #coronavirus #covidhoax <EOS> 2.3524540800963566e-08\n",
            "<BOS1> <BOS2> trump genocide rages trump cheats his wives had pregnancy tests #trumpisanationaldisgrace #covid19 #testing #maga #covididiots #coronavirus #covidhoax #blacklivesmatter #wexit #wescandal <EOS> 2.3524540800963566e-08\n",
            "<BOS1> <BOS2> trump genocide rages trump cheats his wives had pregnancy tests #trumpisanationaldisgrace #covid19 #testing #maga #covididiots #coronavirus #covid_19 URL <EOS> 8.682221686125604e-09\n",
            "<BOS1> <BOS2> trump genocide rages trump cheats his wives had pregnancy tests #trumpisanationaldisgrace #covid19 #testing #maga #covididiots #coronavirus #china #brazil #chicken #scamdemic #plandemic URL <EOS> 4.457281414919413e-09\n",
            "<BOS1> <BOS2> trump genocide rages trump cheats his wives had pregnancy tests #trumpisanationaldisgrace #covid19 #testing #maga #covididiots #coronavirus #china #chinavirus #wuhanvirus #chinaliedpeopledied <EOS> 1.960378400080297e-09\n",
            "<BOS1> <BOS2> trump genocide rages trump cheats his wives had pregnancy tests #trumpisanationaldisgrace #covid19 #testing #maga #covididiots #coronavirus #china #chinavirus #lebanonexplosion #lebanonexplosion #beirutvstianjin #ammonium_nitrate #ammonium #tianjinexplosion beirut versus tianjin explosion ammonium nitrate in pile up for these players are better ways to kill themselves getting covid at this time with my man URL <EOS> 1.3583699061216609e-33\n",
            "--------------------------------------------------\n",
            "<BOS1> <BOS2> biden leads trump follows <EOS> 0.001796945193171608\n",
            "<BOS1> <BOS2> biden tells lin manuel miranda URL <EOS> 0.0010482180293501049\n",
            "<BOS1> <BOS2> biden tells lin manuel miranda latinos ‘ keeping us safe <EOS> 2.09643605870021e-05\n",
            "<BOS1> <BOS2> biden tells lin manuel miranda latinos ‘ keeping us informed URL <EOS> 1.568761676578388e-05\n",
            "<BOS1> <BOS2> biden tells lin manuel miranda latinos keeping us warm #thankyou #coronavirus #twibbon <EOS> 1.497454327643007e-05\n",
            "<BOS1> <BOS2> biden tells lin manuel miranda latinos keeping us warm #thankyou #coronavirus #energyforlife #safeandsoundatwork URL <EOS> 1.497454327643007e-05\n",
            "<BOS1> <BOS2> biden tells lin manuel miranda latinos ‘ keeping us entertained during the peak of 2,500 daily deaths ~10 vs. 1,000 the us govt not mandate them fine anyone do testing with results in under reporting of polls getting commissioned during a #pandemic duh <EOS> 1.3132697216603996e-27\n",
            "<BOS1> <BOS2> biden tells lin manuel miranda latinos ‘ keeping us entertained during the peak of 2,500 daily deaths ~10 vs. 1,000 the us govt not mandate them fine anyone do testing with results in under reporting of polls getting commissioned during a #pandemic discussion of how easy is it possible if we do more to avoid releasing detainees URL <EOS> 5.279099068592031e-44\n",
            "<BOS1> <BOS2> biden tells lin manuel miranda latinos ‘ keeping us entertained during the peak of 2,500 daily deaths ~10 vs. 1,000 the us govt not mandate them fine anyone do testing with results in under reporting of polls getting commissioned during a #pandemic discussion of how easy is it possible if we do more to the bar again <EOS> 1.5045951624924548e-45\n",
            "<BOS1> <BOS2> biden tells lin manuel miranda latinos ‘ keeping us entertained during the peak of 2,500 daily deaths ~10 vs. 1,000 the us govt not mandate them fine anyone do testing with results in under reporting of polls getting commissioned during a #pandemic discussion of how easy is it possible if we do more to avoid releasing detainees URL by @USER is covid-19 is bioweapon created in the dorms this week with a single job lost is the type of dog can smell it it does nothing for the workers are being born and raised in a hospital that was so great i am taking my money is n’t having it <EOS> 2.277292375927974e-112\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UShw7ULDcOwU"
      },
      "source": [
        "# 2. Semantic Parsing\n",
        "\n",
        "In this part, you are going to build your own virtual assistant! We will be developing two modules: an intent classifier and a slot filler."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj2nWqZ9dZUs",
        "outputId": "fd3fd9d7-4673-4a3b-9727-0b0772a381fa"
      },
      "source": [
        "!ls \"/content/drive/My Drive/nl2ds/semantic-parser\"\n",
        "parser_files = \"/content/drive/My Drive/nl2ds/semantic-parser\"\n",
        "# parser_files = \"nl2ds/semantic-parser\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_answers.txt  test_questions.txt  train_questions_answers.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbtOC6eecMNp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebba1af0-6088-4b2d-a6d6-b56131d15c6a"
      },
      "source": [
        "train_data = []\n",
        "for line in open(f'{parser_files}/train_questions_answers.txt'):\n",
        "    train_data.append(json.loads(line))\n",
        "\n",
        "# print a few examples\n",
        "for i in range(5):\n",
        "    print(train_data[i])\n",
        "    print(\"-\"*100)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'question': 'Add an album to my Sylvia Plath playlist.', 'intent': 'AddToPlaylist', 'slots': {'music_item': 'album', 'playlist_owner': 'my', 'playlist': 'Sylvia Plath'}}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "{'question': 'add Diarios de Bicicleta to my la la playlist', 'intent': 'AddToPlaylist', 'slots': {'playlist': 'Diarios de Bicicleta', 'playlist_owner': 'my', 'entity_name': 'la la'}}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "{'question': 'book a table at a restaurant in Lucerne Valley that serves chicken nugget', 'intent': 'BookRestaurant', 'slots': {'restaurant_type': 'restaurant', 'city': 'Lucerne Valley', 'served_dish': 'chicken nugget'}}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "{'question': 'add iemand als jij to my playlist named In The Name Of Blues', 'intent': 'AddToPlaylist', 'slots': {'entity_name': 'iemand als jij', 'playlist_owner': 'my', 'playlist': 'In The Name Of Blues'}}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "{'question': 'What will the weather be in the current position on Dec. 23?', 'intent': 'GetWeather', 'slots': {'current_location': 'current position', 'timeRange': 'Dec. 23'}}\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMV-NkkAb6X3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f07aac3e-8e24-4649-e69a-14b308e86272"
      },
      "source": [
        "test_questions = []\n",
        "for line in open(f'{parser_files}/test_questions.txt'):\n",
        "    test_questions.append(json.loads(line))\n",
        "\n",
        "test_answers = []\n",
        "for line in open(f'{parser_files}/test_answers.txt'):\n",
        "    test_answers.append(json.loads(line))\n",
        "\n",
        "# print a few examples\n",
        "for i in range(5):\n",
        "    print(test_questions[i])\n",
        "    print(test_answers[i])\n",
        "    print(\"-\"*100)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Add an artist to Jukebox Boogie Rhythm & Blues\n",
            "{'intent': 'AddToPlaylist', 'slots': {'music_item': 'artist', 'playlist': 'Jukebox Boogie Rhythm & Blues'}}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Will it be rainy at Sunrise in Ramey Saudi Arabia?\n",
            "{'intent': 'GetWeather', 'slots': {'condition_description': 'rainy', 'timeRange': 'Sunrise', 'city': 'Ramey', 'country': 'Saudi Arabia'}}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Weather in two hours  in Uzbekistan\n",
            "{'intent': 'GetWeather', 'slots': {'timeRange': 'in two hours', 'country': 'Uzbekistan'}}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Will there be a cloud in VI in 14 minutes ?\n",
            "{'intent': 'GetWeather', 'slots': {'condition_description': 'cloud', 'state': 'VI', 'timeRange': 'in 14 minutes'}}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "add nuba to my Metal Party playlist\n",
            "{'intent': 'AddToPlaylist', 'slots': {'entity_name': 'nuba', 'playlist_owner': 'my', 'playlist': 'Metal Party'}}\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLUozTj613Tk"
      },
      "source": [
        "## Problem 2.1: Keyword-based intent classifier\n",
        "\n",
        "In this part, you will build a keyword-based intent classifier. For each intent, come up with a list of keywords that are important for that intent, and then classify a given question into an intent. If an input question matches multiple intents, pick the best one. If it does not match any keyword, return None.\n",
        "\n",
        "Caution: You are allowed to look at training questions and answers to come up with a set of keywords, but it is a bad practice to look at test answers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIOcz3lC4VqP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "181de769-5137-4b5f-d571-af5a927684bd"
      },
      "source": [
        "# list of all intents\n",
        "intents = set()\n",
        "for example in train_data:\n",
        "    intents.add(example['intent'])\n",
        "print(intents)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'BookRestaurant', 'AddToPlaylist', 'GetWeather'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmpLWuCO46NG"
      },
      "source": [
        "# 1. Get top 50 words for each intent by frequency\n",
        "# 2. Manually choose 12 words as keywords\n",
        "# 3. Predict intent based on number of matches to keyword lists\n",
        "\n",
        "def get_keywords(train_data, intents, n=50):\n",
        "    keywords = {intent:{} for intent in intents}\n",
        "    \n",
        "    for data in train_data:\n",
        "        intent = data['intent']\n",
        "        if intent in keywords:\n",
        "            question = data['question'].lower()\n",
        "            question_copy = question\n",
        "            \n",
        "            # replace punctuation with space\n",
        "            for c in question_copy:\n",
        "                if c in string.punctuation:\n",
        "                    question = question.replace(c, ' ')\n",
        "                    \n",
        "            # split question by space\n",
        "            question = question.split()\n",
        "                    \n",
        "            for word in question:\n",
        "                if word.isalpha():\n",
        "                    if word in keywords[intent]:\n",
        "                        keywords[intent][word] += 1\n",
        "                    else:\n",
        "                        keywords[intent][word] = 1\n",
        "                    \n",
        "    n_keywords = {intent:[] for intent in intents}\n",
        "    \n",
        "    for intent in keywords:\n",
        "        sorted_intent = dict(sorted(keywords[intent].items(), key=lambda item: item[1], reverse=True))\n",
        "        \n",
        "        sorted_keys = list(sorted_intent.keys())\n",
        "        n_keywords[intent] = sorted_keys[:n]\n",
        "        \n",
        "    return n_keywords\n",
        "\n",
        "# classify a given question into an intent\n",
        "def predict_intent_using_keywords(question):\n",
        "    # fill in your code here\n",
        "    \n",
        "    # for each intent, come up with a list of keywords that are improtant for that intent\n",
        "    # look at training questions and answers to come up with a set of keywords\n",
        "    keywords_p = ['add', 'playlist', 'tune', 'song', 'music', 'track', 'album', 'artist', 'metal', 'rock', 'indie', 'pop']\n",
        "    keywords_w = ['weather', 'forecast', 'current', 'hot', 'warm', 'cold', 'chill', 'freezing', 'area', 'what', 'tell', 'park']\n",
        "    keywords_r = ['book', 'restaurant', 'table', 'reservation', 'serve', 'spot', 'rated', 'food', 'bar', 'eat', 'two', 'make']\n",
        "\n",
        "    n_keywords = {'AddToPlaylist': keywords_p, 'GetWeather': keywords_w, 'BookRestaurant': keywords_r}\n",
        "    \n",
        "    count_p = 0\n",
        "    count_w = 0\n",
        "    count_r = 0\n",
        "\n",
        "    for k in keywords_p:\n",
        "        if k in question:\n",
        "            count_p += 1\n",
        "            \n",
        "    for k in keywords_w:\n",
        "        if k in question:\n",
        "            count_w += 1\n",
        "            \n",
        "    for k in keywords_r:\n",
        "        if k in question:\n",
        "            count_r += 1\n",
        "    \n",
        "    all_counts = {'AddToPlaylist': count_p, 'GetWeather': count_w, 'BookRestaurant': count_r}    \n",
        "    sorted_counts = dict(sorted(all_counts.items(), key=lambda item: item[1], reverse=True))\n",
        "        \n",
        "    sorted_keys = list(sorted_counts.keys())\n",
        "    \n",
        "    return sorted_keys[0]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSNHoHR16jk9",
        "outputId": "b0716ec2-a7e3-4b21-f807-ebd68b362257"
      },
      "source": [
        "'''Gives intent wise accuracy of your model'''\n",
        "def evaluate_intent_accuracy(prediction_function_name):\n",
        "    correct = Counter()\n",
        "    total = Counter()\n",
        "    for i in range(len(test_questions)):\n",
        "        q = test_questions[i]\n",
        "        gold_intent = test_answers[i]['intent']\n",
        "        if prediction_function_name(q) == gold_intent:\n",
        "            correct[gold_intent] += 1\n",
        "        total[gold_intent] += 1\n",
        "    for intent in intents:\n",
        "        print(intent, correct[intent]/total[intent], total[intent])\n",
        "    \n",
        "# Evaluating the intent classifier. \n",
        "# In our implementation, a simple keyword based classifier has achieved an accuracy of greater than 65 for each intent\n",
        "evaluate_intent_accuracy(predict_intent_using_keywords)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BookRestaurant 0.97 100\n",
            "AddToPlaylist 1.0 100\n",
            "GetWeather 0.78 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzV5NYJe-rbm"
      },
      "source": [
        "## Problem 2.2: Statistical intent classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jizp2fxbb6X5"
      },
      "source": [
        "Now, let's build a statistical intent classifier. Instead of making use of keywords like what you did above, you will first extract features from a given input question. In order to build a feature representation for a given sentence, make use of word2vec embeddings of each word and take an average to represent the sentence. Then train a logistic regression. Feel free to use any libraries you like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iys8Cb3An3x"
      },
      "source": [
        "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))\n",
        "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_sample, binary=False)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract features from a given input question\n",
        "# to build a feature representation for a given sentence, make use of word2vec embeddings of each word and\n",
        "# take an average to represent the sentence\n",
        "def build_sentence_features(question):    \n",
        "    question = question.lower()\n",
        "    question_copy = question\n",
        "\n",
        "    # replace punctuation with space\n",
        "    for c in question_copy:\n",
        "        if c in string.punctuation:\n",
        "            question = question.replace(c, ' ')\n",
        "\n",
        "    # split question by space\n",
        "    question = question.split()\n",
        "    \n",
        "    count = 0\n",
        "    for word in question:\n",
        "        if word in word2vec_model:\n",
        "            word_embedding = word2vec_model[word]\n",
        "            word_embedding = np.array([word_embedding])\n",
        "        # word embedding filled with zeros\n",
        "        else:\n",
        "            word_embedding = np.zeros((1,300))\n",
        "            \n",
        "        if count == 0:\n",
        "            all_embeddings = word_embedding\n",
        "            count += 1\n",
        "        else:\n",
        "            all_embeddings = np.concatenate((all_embeddings, word_embedding), axis=0)\n",
        "            \n",
        "    average = np.mean(all_embeddings, axis=0)\n",
        "            \n",
        "    return average\n",
        "                \n",
        "def get_X(train_data):\n",
        "    count = 0\n",
        "    \n",
        "    for data in train_data:\n",
        "        question = data['question']\n",
        "        average = build_sentence_features(question)\n",
        "        average = np.array([average])\n",
        "        \n",
        "        if count == 0:\n",
        "            X = average\n",
        "            count += 1\n",
        "        else:\n",
        "            X = np.concatenate((X, average), axis=0)\n",
        "            \n",
        "    return X\n",
        "\n",
        "def get_y(train_data):\n",
        "    count = 0\n",
        "    \n",
        "    for data in train_data:\n",
        "        intent = data['intent']\n",
        "        \n",
        "        if count == 0:\n",
        "            y = np.array([intent])\n",
        "            count += 1\n",
        "        else:\n",
        "            y = np.append(y, [intent])\n",
        "            \n",
        "    return y\n",
        "            \n",
        "X_train = get_X(train_data)\n",
        "y_train = get_y(train_data)"
      ],
      "metadata": {
        "id": "M1alqLu2OMBG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpk3_JtMb6X6"
      },
      "source": [
        "'''Trains a logistic regression model on the entire training data. For an input question (x), the model learns to predict an intent (Y).'''\n",
        "def train_logistic_regression_intent_classifier():\n",
        "    # fill in your code here\n",
        "    lr_model = LogisticRegression()\n",
        "    lr_model.fit(X_train, y_train)\n",
        "    \n",
        "    return lr_model\n",
        "\n",
        "lr_model = train_logistic_regression_intent_classifier()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_1lHAw9b6X6"
      },
      "source": [
        "'''For an input question, the model predicts an intent'''\n",
        "def predict_intent_using_logistic_regression(question):\n",
        "    # fill in your code here\n",
        "    X_test = np.array([build_sentence_features(question)])\n",
        "    C = lr_model.predict(X_test)\n",
        "    \n",
        "    return C"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBwjBJoUb6X7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ca6440e-49f6-4740-d07e-5e2a574e3eae"
      },
      "source": [
        "# evaluate the intent classifier\n",
        "# your intent classifier performance will be close to 100 if you have done a good job\n",
        "evaluate_intent_accuracy(predict_intent_using_logistic_regression)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BookRestaurant 1.0 100\n",
            "AddToPlaylist 1.0 100\n",
            "GetWeather 1.0 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUnGNOHNXbSN"
      },
      "source": [
        "## Problem 2.3: Slot filling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONXIMs6_b6X7"
      },
      "source": [
        "Build a slot filling model. We will just work with `AddToPlaylist` intent. Ignore other intents.\n",
        "\n",
        "Hint: No need to rely on machine learning here. You can use ideas like maximum string matching to identify which slots are active and what thier values are. This problem's solution is intentionally left underspecified."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpg1x-qeb6X7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e5f3457-4f2d-4aea-f5c0-b501e8297169"
      },
      "source": [
        "# let's stick to one target intent\n",
        "target_intent = \"AddToPlaylist\"\n",
        "\n",
        "# this intent has the following slots\n",
        "target_intent_slot_names = set()\n",
        "for sample in train_data:\n",
        "    if sample['intent'] == target_intent:\n",
        "        for slot_name in sample['slots']:\n",
        "            target_intent_slot_names.add(slot_name)\n",
        "print(target_intent_slot_names)\n",
        "\n",
        "# extract all the relevant questions of this target intent from the test examples\n",
        "target_intent_questions = [] \n",
        "for i, question in enumerate(test_questions):\n",
        "    if test_answers[i]['intent'] == target_intent:\n",
        "        target_intent_questions.append(question)\n",
        "print(len(target_intent_questions))\n",
        "\n",
        "# extract all the relevant questions of this target intent from the train examples\n",
        "target_intent_data = [] \n",
        "for sample in train_data:\n",
        "    if sample['intent'] == target_intent:\n",
        "        target_intent_data.append(sample)\n",
        "print(len(target_intent_data))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'playlist', 'music_item', 'playlist_owner', 'artist', 'entity_name'}\n",
            "100\n",
            "1942\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7_ldSKob6X8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "190fd92c-7e94-4d41-dfb8-a3151ad4bec8"
      },
      "source": [
        "def initialize_slots():\n",
        "    slots = {}\n",
        "    for slot_name in target_intent_slot_names:\n",
        "        slots[slot_name] = None\n",
        "\n",
        "    for data in target_intent_data:\n",
        "        for slot_name in data['slots']:\n",
        "            if slots[slot_name] == None:\n",
        "                slots[slot_name] = set()\n",
        "            \n",
        "            cleaned_value = data['slots'][slot_name].lower()\n",
        "            slots[slot_name].add(cleaned_value)\n",
        "            \n",
        "    for slot_name in slots:\n",
        "        sorted_values = sorted(slots[slot_name])\n",
        "        slots[slot_name] = sorted_values\n",
        "\n",
        "    return slots\n",
        "\n",
        "def predict_slot_values(question):\n",
        "    slots = initialize_slots()\n",
        "    predicted_slots = {}\n",
        "    for slot_name in target_intent_slot_names:\n",
        "        # fill in your code to idenfity the slot value\n",
        "        predicted_slots[slot_name] = None\n",
        "\n",
        "        for unique_value in slots[slot_name]:\n",
        "            if unique_value in question.lower():\n",
        "                predicted_slots[slot_name] = unique_value\n",
        "            \n",
        "    return predicted_slots\n",
        "\n",
        "def evaluate_slot_prediction_recall(slot_prediction_function):\n",
        "    correct = Counter()\n",
        "    total = Counter()\n",
        "    # predict slots for each question\n",
        "    for i, question in enumerate(target_intent_questions):\n",
        "        i = test_questions.index(question) \n",
        "        gold_slots = test_answers[i]['slots']\n",
        "        predicted_slots = slot_prediction_function(question)\n",
        "        for name in target_intent_slot_names:\n",
        "            if name in gold_slots:\n",
        "                total[name] += 1.0\n",
        "                if (predicted_slots.get(name, None) != None) and (predicted_slots.get(name).lower() == gold_slots.get(name).lower()): # This line is updated after the assignment release\n",
        "                    correct[name] += 1.0\n",
        "                # else:\n",
        "                    # print(predicted_slots.get(name), '|', gold_slots.get(name))\n",
        "    for name in target_intent_slot_names:\n",
        "        print(f\"{name}: {correct[name] / total[name]}\")\n",
        "\n",
        "\n",
        "# Our reference implementation got these numbers. You can ask others on Slack what they got.\n",
        "# music_item 1.0\n",
        "# playlist 0.67\n",
        "# artist  0.021739130434782608\n",
        "# playlist_owner 0.9444444444444444\n",
        "# entity_name 0.05555555555555555\n",
        "print(\"Slot accuracy for your slot prediction model\")\n",
        "evaluate_slot_prediction_recall(predict_slot_values)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slot accuracy for your slot prediction model\n",
            "playlist: 0.81\n",
            "music_item: 1.0\n",
            "playlist_owner: 0.9444444444444444\n",
            "artist: 0.13043478260869565\n",
            "entity_name: 0.05555555555555555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lm4reFpdb6X8"
      },
      "source": [
        "def tp_fp_tn_fn(slot_prediction_function):\n",
        "    tp_list = []\n",
        "    fp_list = []\n",
        "    tn_list = []\n",
        "    fn_list = []\n",
        "\n",
        "    # predict slots for each question\n",
        "    for i, question in enumerate(target_intent_questions):\n",
        "        i = test_questions.index(question) \n",
        "        gold_slots = test_answers[i]['slots']\n",
        "        predicted_slots = slot_prediction_function(question)\n",
        "        for name in target_intent_slot_names:\n",
        "            if name in gold_slots:\n",
        "                if (predicted_slots.get(name, None) != None) and (predicted_slots.get(name).lower() == gold_slots.get(name).lower()): # This line is updated after the assignment release\n",
        "                    tp = {}\n",
        "                    tp['Question'] = question\n",
        "                    tp['Ground truth slots'] = gold_slots\n",
        "                    tp['Predicted'] = {name: predicted_slots.get(name, None)}\n",
        "                    tp_list.append(tp)\n",
        "                    # break\n",
        "                elif (predicted_slots.get(name, None) == None):\n",
        "                    fn = {}\n",
        "                    fn['Question'] = question\n",
        "                    fn['Ground truth slots'] = gold_slots\n",
        "                    fn['Predicted'] = {name: predicted_slots.get(name, None)}\n",
        "                    fn_list.append(fn)\n",
        "                    # break\n",
        "            else:\n",
        "                if (predicted_slots.get(name, None) == None):\n",
        "                    tn = {}\n",
        "                    tn['Question'] = question\n",
        "                    tn['Ground truth slots'] = gold_slots\n",
        "                    tn['Predicted'] = {name: predicted_slots.get(name, None)}\n",
        "                    tn_list.append(tn)\n",
        "                    # break\n",
        "                elif (predicted_slots.get(name, None) != None):\n",
        "                    fp = {}\n",
        "                    fp['Question'] = question\n",
        "                    fp['Ground truth slots'] = gold_slots\n",
        "                    fp['Predicted'] = {name: predicted_slots.get(name, None)}\n",
        "                    fp_list.append(fp)\n",
        "                    # break\n",
        "\n",
        "    return tp_list, fp_list, tn_list, fn_list\n",
        "\n",
        "tp_list, fp_list, tn_list, fn_list = tp_fp_tn_fn(predict_slot_values)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find a true positive prediction for each slot\n",
        "# fill in your code below along with printing your prediction and gold answer\n",
        "for i in range(3):\n",
        "    print('Question:', tp_list[i]['Question'])\n",
        "    print('Ground truth slots:', tp_list[i]['Ground truth slots'])\n",
        "    print('Predicted:', tp_list[i]['Predicted'])\n",
        "    print('--------------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKpFE8HL2jSs",
        "outputId": "66a31213-ccf0-4b79-dfc0-0e30ff3cf077"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Add an artist to Jukebox Boogie Rhythm & Blues\n",
            "Ground truth slots: {'music_item': 'artist', 'playlist': 'Jukebox Boogie Rhythm & Blues'}\n",
            "Predicted: {'playlist': 'jukebox boogie rhythm & blues'}\n",
            "--------------------------------------------------\n",
            "Question: Add an artist to Jukebox Boogie Rhythm & Blues\n",
            "Ground truth slots: {'music_item': 'artist', 'playlist': 'Jukebox Boogie Rhythm & Blues'}\n",
            "Predicted: {'music_item': 'artist'}\n",
            "--------------------------------------------------\n",
            "Question: add nuba to my Metal Party playlist\n",
            "Ground truth slots: {'entity_name': 'nuba', 'playlist_owner': 'my', 'playlist': 'Metal Party'}\n",
            "Predicted: {'playlist_owner': 'my'}\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUo4NblMb6X8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ee6eceb-a607-45ab-bb92-f5288502d827"
      },
      "source": [
        "# find a false positive prediction for each slot\n",
        "# fill in your code below along with print statement\n",
        "for i in range(3):\n",
        "    print('Question:', fp_list[i]['Question'])\n",
        "    print('Ground truth slots:', fp_list[i]['Ground truth slots'])\n",
        "    print('Predicted:', fp_list[i]['Predicted'])\n",
        "    print('--------------------------------------------------')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Can you put this song from Yutaka Ozaki onto my this is miles davis playlist?\n",
            "Ground truth slots: {'music_item': 'song', 'artist': 'Yutaka Ozaki', 'playlist_owner': 'my', 'playlist': 'this is miles davis'}\n",
            "Predicted: {'entity_name': 'om'}\n",
            "--------------------------------------------------\n",
            "Question: Add porter wagoner to the The Sleep Machine Waterscapes playlist.\n",
            "Ground truth slots: {'artist': 'porter wagoner', 'playlist': 'The Sleep Machine Waterscapes'}\n",
            "Predicted: {'entity_name': 'go'}\n",
            "--------------------------------------------------\n",
            "Question: Add the chris clark tune to my women of the blues playlist.\n",
            "Ground truth slots: {'artist': 'chris clark', 'music_item': 'tune', 'playlist_owner': 'my', 'playlist': 'women of the blues'}\n",
            "Predicted: {'entity_name': 'om'}\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQjb1-TCb6X8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44f9c911-43ec-48a3-b540-ad40d684365c"
      },
      "source": [
        "# find a true negative prediction for each slot\n",
        "# fill in your code below along with a print statement\n",
        "for i in range(3):\n",
        "    print('Question:', tn_list[i]['Question'])\n",
        "    print('Ground truth slots:', tn_list[i]['Ground truth slots'])\n",
        "    print('Predicted:', tn_list[i]['Predicted'])\n",
        "    print('--------------------------------------------------')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Add an artist to Jukebox Boogie Rhythm & Blues\n",
            "Ground truth slots: {'music_item': 'artist', 'playlist': 'Jukebox Boogie Rhythm & Blues'}\n",
            "Predicted: {'playlist_owner': None}\n",
            "--------------------------------------------------\n",
            "Question: Add an artist to Jukebox Boogie Rhythm & Blues\n",
            "Ground truth slots: {'music_item': 'artist', 'playlist': 'Jukebox Boogie Rhythm & Blues'}\n",
            "Predicted: {'artist': None}\n",
            "--------------------------------------------------\n",
            "Question: Add an artist to Jukebox Boogie Rhythm & Blues\n",
            "Ground truth slots: {'music_item': 'artist', 'playlist': 'Jukebox Boogie Rhythm & Blues'}\n",
            "Predicted: {'entity_name': None}\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJHTfEMqb6X8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3fa6479-c8ee-48ab-d393-921e78e1d62b"
      },
      "source": [
        "# find a false negative prediction for each slot\n",
        "# fill in your code below along with a print statement\n",
        "for i in range(3):\n",
        "    print('Question:', fn_list[i]['Question'])\n",
        "    print('Ground truth slots:', fn_list[i]['Ground truth slots'])\n",
        "    print('Predicted:', fn_list[i]['Predicted'])\n",
        "    print('--------------------------------------------------')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: add nuba to my Metal Party playlist\n",
            "Ground truth slots: {'entity_name': 'nuba', 'playlist_owner': 'my', 'playlist': 'Metal Party'}\n",
            "Predicted: {'entity_name': None}\n",
            "--------------------------------------------------\n",
            "Question: Add the album to the The Sweet Suite playlist.\n",
            "Ground truth slots: {'music_item': 'album', 'playlist': 'The Sweet Suite'}\n",
            "Predicted: {'playlist': None}\n",
            "--------------------------------------------------\n",
            "Question: Can you put this song from Yutaka Ozaki onto my this is miles davis playlist?\n",
            "Ground truth slots: {'music_item': 'song', 'artist': 'Yutaka Ozaki', 'playlist_owner': 'my', 'playlist': 'this is miles davis'}\n",
            "Predicted: {'playlist': None}\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4Ap9x2LQ3HYM"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}